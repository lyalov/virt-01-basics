Домашнее задание к занятию 1. «Введение в виртуализацию»

Ялова Л.В.

Задача 1
Ознакомьтесь с инструкцией по экономии облачных ресурсов.

Создайте через web-интерфейс Yandex Cloud - VPC и виртуальную машину из инструкции конфигурации "эконом-ВМ" с публичным ip-адресом. В пункте "Выбор образа/загрузочного диска" выберите вкладку "Cloud Marketplace" , щелкните "Посмотреть больше", найдите образ "Yandex Cloud Toolbox".
Убедитесь, что вы можете подключиться к консоли ВМ через ssh, используя публичный ip-адрес. Убедитесь, что на ВМ установлен Docker с помощью команды docker --version(команду выполните от имени root пользователя) !
Узнайте в инструкции Яндекс, какие еще инструменты предустановлены в данном образе.
Оставьте ВМ работать, пока она не выключится самостоятельно! Опция "прерываемая" выключит ее не позже чем через 24 часа.
Для наглядности подождите еще 1 сутки.
Перейдите по ссылке . Выберите свой платежный аккаунт. Перейдите на вкладку детализация (фильтр "По продуктам") и оцените график потребления финансов.
Удалите ВМ или пользуйтесь ею при выполнении последующих домашних заданий курса обучения.


ОТВЕТ1
создание вм :
![alt text]( create_vm.png
connect_vm.png
docker_version.png
billing_vm.png

Инструмены
Docker
Kubernetes CLI (kubectl)
Terraform
YC CLI (yc)
Git
Curl / Wget
Python 3 и  так далее полный список тут 
https://yandex.cloud/ru/search?q=%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B&type=doc


 Задача 2
Выберите один из вариантов платформы в зависимости от задачи. Здесь нет однозначно верного ответа так как все зависит от конкретных условий: финансирование, компетенции специалистов, удобство использования, надежность, требования ИБ и законодательства, фазы луны.

Тип платформы:

физические сервера;
паравиртуализация;
виртуализация уровня ОС;
Задачи:

высоконагруженная база данных MySql, критичная к отказу;
различные web-приложения;
Windows-системы для использования бухгалтерским отделом;
системы, выполняющие высокопроизводительные расчёты на GPU.
Объясните критерии выбора платформы в каждом случае.

 ОТВЕТ2

1. Высоконагруженная база данных MySQL, критичная к отказу
  Физические сервера
MySQL — I/O-интенсивная система, требует максимальной производительности дисков и сети.
На физических серверах нет оверхеда гипервизора → меньше задержки, выше пропускная способность.
Для отказоустойчивости можно использовать кластер (Galera, MHA) + резервирование на аппаратном уровне.
Виртуализация может добавить непредсказуемые задержки при нагрузке, особенно если соседние ВМ "шумят".
Альтернатива: Если нужно масштабируемость и управляемость — паравиртуализация (KVM) с выделенными ресурсами (CPU pinning, dedicated storage), но цена и сложность выше.

2. Различные web-приложения
  Виртуализация уровня ОС (контейнеры)
Web-приложения часто имеют небольшую нагрузку, легко масштабируются.
Контейнеры (Docker + Kubernetes) обеспечивают:
Быстрый запуск/остановку.
Изоляцию между приложениями.
Легкую миграцию и деплой.
Эффективное использование ресурсов (меньше overhead, чем VM).
Можно использовать serverless или managed container services (Yandex Managed Service for Kubernetes).
 Альтернатива: Для legacy-приложений или если нужны полные ОС — паравиртуализация (KVM).

3. Windows-системы для бухгалтерского отдела
 Подойдет паравиртуализация (KVM/QEMU)
Windows требует полноценной виртуальной машины (не работает в контейнерах на Linux-хосте без Hyper-V).
Паравиртуализация обеспечивает: Полную совместимость с Windows. Хорошую производительность (VirtIO drivers).
Возможность использования RDP для удаленного доступа.
Физические серверы — избыточны (дорого, сложно масштабировать).
Контейнеры — не подходят (Windows Server Containers возможны, но только на Windows-хосте, что неэффективно).
 Альтернатива: Облачные десктопы (VDI) — например, Yandex Cloud Desktops, если нужна централизованная управляемость.

4. Системы, выполняющие высокопроизводительные расчёты на GPU
 Физические сервера лучше использовать 
GPU-вычисления (ML, Deep Learning, rendering) требуют прямого доступа к видеокарте.
Виртуализация уровня ОС — не поддерживает GPU без специальных драйверов и passthrough.
Паравиртуализация — возможна, но с потерей производительности ,если используется vGPU или GPU passthrough — тогда почти как физический сервер.
Физические серверы:
Максимальная производительность.
Прямой доступ к GPU  , как пример NVIDIA CUDA.
Минимальный оверхед.


Задача 3
Выберите подходящую систему управления виртуализацией для предложенного сценария. Опишите ваш выбор.
Сценарии:
100 виртуальных машин на базе Linux и Windows, общие задачи, нет особых требований. Преимущественно Windows based-инфраструктура, требуется реализация программных балансировщиков нагрузки, репликации данных и автоматизированного механизма создания резервных копий.
Требуется наиболее производительное бесплатное open source-решение для виртуализации небольшой (20-30 серверов) инфраструктуры на базе Linux и Windows виртуальных машин.
Необходимо бесплатное, максимально совместимое и производительное решение для виртуализации Windows-инфраструктуры.
Необходимо рабочее окружение для тестирования программного продукта на нескольких дистрибутивах Linux.

ОТВЕТ 3
Сценарий 1
100 ВМ на базе Linux и Windows, преимущественно Windows-инфраструктура. 
Требуется:
Программные балансировщики нагрузки,репликация данных,автоматизированное резервное копирование. Microsoft Hyper-V + System Center Virtual Machine Manager (SCVMM)
Или, если не используется SCVMM — Hyper-V в сочетании с Windows Admin Center и PowerShell-автоматизацией.
Hyper-V — родная платформа для Windows, обеспечивает наилучшую совместимость, производительность и поддержку (особенно для Active Directory, SQL Server, IIS и т.п.).
Встроенные механизмы репликации (Hyper-V Replica) позволяют реплицировать ВМ между хостами без стороннего ПО.
Возможна интеграция с Windows Server Failover Clustering (WSFC) и Storage Spaces Direct для отказоустойчивости.
Балансировка нагрузки: можно использовать Windows Server NLB или, лучше, Azure Load Balancer / Application Gateway, если часть инфраструктуры мигрирует в облако. Либо third-party решения (HAProxy, NGINX) на отдельных ВМ.
Резервное копирование: Windows Server Backup, Veeam Backup & Replication (есть бесплатная Community Edition), или System Center Data Protection Manager (DPM).
Hyper-V хорошо масштабируется до сотен ВМ при наличии кластера и централизованного управления.
Альтернатива: VMware vSphere + vCenter + vSphere Replication + NSX (для балансировки и сетевой виртуализации). Но это платное решение, а в условии не указан бюджет — однако упоминается "Windows-based инфраструктура", что делает Hyper-V более логичным выбором.

Сценарий 2
Производительное, бесплатное open-source решение для 20–30 серверов (Linux + Windows).
Рекомендуемая система: oVirt , PVE (на базе KVM)
Или его коммерческий аналог — Red Hat Virtualization (RHV), но он платный.
oVirt — мощная open-source платформа управления KVM, поддерживает как Linux, так и Windows (с установкой VirtIO-драйверов).
Обеспечивает:
централизованное управление кластером,
live migration,
storage domains (NFS, iSCSI, GlusterFS, Ceph),
встроенную систему резервного копирования (с помощью скриптов или внешних инструментов),
HA (High Availability) для ВМ.
Бесплатна, активно развивается, совместима с enterprise-средами.
Поддерживает балансировку через внешние ВМ (например, HAProxy в отдельной ВМ).
Производительность KVM близка к "bare metal", особенно при правильной настройке (CPU pinning, huge pages и т.д.).
Альтернатива:
Proxmox VE — также на базе KVM + LXC, с удобным веб-интерфейсом, встроенными резервными копиями, ZFS-поддержкой. Очень популярен в SMB.
На практике Proxmox VE часто предпочтительнее из-за простоты и готовых функций.
Рекомендация: Proxmox VE — если нужна максимальная простота и готовые функции "из коробки".
 Итоговый выбор: Proxmox VE
(KVM + веб-интерфейс + резервное копирование + кластеризация + бесплатная лицензия)

Сценарий 3
Бесплатное, максимально совместимое и производительное решение для виртуализации Windows-инфраструктуры.
Рекомендуемая система: Microsoft Hyper-V (в составе Windows Server)
Или Hyper-V Server (бесплатная standalone-версия Windows Server Core с только Hyper-V).
Hyper-V Server — бесплатен, включает только гипервизор и необходимые компоненты.
Полная совместимость с Windows-гостями: нет проблем с драйверами, лицензированием, обновлениями.
Высокая производительность: особенно при использовании Generation 2 ВМ, Dynamic Memory, Offload-технологий.
Поддержка всех enterprise-фич: live migration, failover clustering, replication.
Можно управлять через Windows Admin Center (бесплатный веб-интерфейс от Microsoft).
 Почему не VMware?
VMware ESXi бесплатен (Free Hypervisor), но:
ограничен в API (нельзя автоматизировать резервное копирование без платной лицензии),
для Windows требуются отдельные драйверы,менее "родной" по сравнению с Hyper-V.
 Почему не KVM?
VM поддерживает Windows, но:
требует установки VirtIO-драйверов,
возможны нюансы с лицензированием,
производительность диска/сети может уступать без тонкой настройки.
 Вывод: Hyper-V Server (бесплатный) — лучший выбор по совместимости, производительности и стоимости.


 Сценарий 4
Рабочее окружение для тестирования ПО на нескольких дистрибутивах Linux.

 Docker + Podman (для контейнеров) + Vagrant (для полноценных ВМ)
Если тестируется приложение, не зависящее от ядра ОС — Docker идеален:
мгновенный запуск разных дистрибутивов (ubuntu:22.04, centos:7, alpine, debian:bookworm и т.д.),
изоляция,
легковесность.
Если тестируется низкоуровневое ПО, requiring full OS boot (например, systemd, kernel modules, init-скрипты) — использовать Vagrant + VirtualBox или Vagrant + libvirt (KVM).
Vagrant позволяет описать окружение в Vagrantfile.
Поддерживает десятки образов Linux.
Локальное, быстрое, бесплатное.
Альтернатива:
Multipass (от Canonical) — для быстрого запуска Ubuntu-ВМ.
systemd-nspawn — легковесная контейнеризация на уровне ОС.
Но Vagrant + VirtualBox — самый универсальный и кроссплатформенный подход.
Итог:
Для большинства задач тестирования → Docker
Для full-OS тестов → Vagrant с VirtualBox или KVM


Задача 4
Опишите возможные проблемы и недостатки гетерогенной среды виртуализации (использования нескольких систем управления виртуализацией одновременно) и что необходимо сделать для минимизации этих рисков и проблем. Если бы у вас был выбор, создавали бы вы гетерогенную среду или нет?

ОТВЕТ 4: Гетерогенная среда виртуализации — проблемы, риски и рекомендации
Что такое гетерогенная среда виртуализации?
Это инфраструктура, в которой одновременно используются разные системы управления виртуализацией ,например: VMware vSphere, Microsoft Hyper-V и KVM/oVirt/Proxmox — либо в разных подразделениях, либо даже в рамках одного ЦОД.

Основные проблемы и недостатки гетерогенной среды
Сложность управления и мониторинга
Каждая платформа имеет свой интерфейс, API, логику ресурсов, терминологию.
Требуются разные инструменты для сбора метрик, алертинга, резервного копирования.
Отсутствие единой панели управления (single pane of glass).
Повышенные требования к квалификации персонала
Администраторы должны знать особенности всех платформ.
Риск ошибок при переключении между системами.
Сложнее обучать новых сотрудников.
Проблемы с переносимостью и совместимостью
ВМ, созданные в одной системе (например, VMware), нельзя напрямую запустить в другой (например, Hyper-V).
Требуются конвертации образов (VMDK → VHDX → QCOW2), которые могут нарушить стабильность системы.
Драйверы, интеграционные сервисы (VMware Tools, Hyper-V Integration Services) несовместимы.
Усложнение автоматизации и DevOps-процессов
CI/CD-пайплайны, IaC-скрипты (Terraform, Ansible) требуют отдельных модулей под каждую платформу.
Увеличение сложности кода и тестирования.
Неравномерное использование ресурсов
Невозможно эффективно балансировать нагрузку между кластерами разных гипервизоров.
Риск "островов ресурсов" — одни серверы перегружены, другие простаивают.
Повышенные операционные расходы (OPEX)
Лицензирование (если используется коммерческое ПО).
Поддержка нескольких стеков технологий.
Дублирование функций (резервное копирование, мониторинг и т.д.).
Сложность обеспечения ИБ и соответствия требованиям
Разные политики безопасности, аудита, шифрования.
Труднее сертифицировать гетерогенную инфраструктуру под стандарты (ISO 27001, ГОСТ, PCI DSS и др.).
Как минимизировать риски гетерогенной среды?
Централизованное управление через унифицированные инструменты
Использовать мультигипервизорные платформы, например:
Terraform — для развертывания инфраструктуры.
Red Hat Ansible — для конфигурации.
OpenStack (с гипервизорами в качестве бэкендов).
Cloud Management Platforms (CMP) — например, ManageIQ, VMware vRealize (ограниченно).
Стандартизация процессов и политик
Единые стандарты именования, сетевой сегментации, резервного копирования.
Общие runbook’и и процедуры восстановления.
Обучение и кросс-функциональные команды
Обучать администраторов работе с несколькими платформами.
Создавать "центры компетенций" по каждому гипервизору при необходимости.
Ограничить гетерогенность только там, где она оправдана
Например:
Hyper-V — для Windows-нагрузок.
KVM/Proxmox — для Linux и open-source.
Но не использовать 3+ платформ без веской причины.
Автоматизировать конвертацию и миграцию (при необходимости)
Использовать инструменты вроде StarWind V2V Converter, qemu-img, VMware OVF Tool.
Тестировать миграции в staging-среде.
Внедрить единый мониторинг
Prometheus + Grafana + exporters для каждой платформы.
ELK-стек или Splunk для централизованных логов.
Создавал бы я гетерогенную среду, если бы был выбор?
Ответ: Только при наличии веских обоснованных причин.

Когда гетерогенность допустима (и даже полезна):
Слияние компаний с разными ИТ-ландшафтами (M&A).
Специфические требования приложений (например, Windows-СУБД + Linux-HPC).
Постепенная миграция с одной платформы на другую.
Использование облачных и локальных решений одновременно (hybrid cloud).
Когда лучше избегать:
В новой инфраструктуре "с нуля".
При ограниченных ресурсах ИТ-отдела.
Если нет явных технических или лицензионных ограничений.
Мой выбор:
Стремиться к гомогенной среде (один гипервизор) — это проще, дешевле и надёжнее.
Гетерогенность — исключение, а не правило. Её следует применять осознанно и временно, с чётким планом консолидации.

Вывод
Гетерогенная среда виртуализации несёт значительные операционные, технические и финансовые издержки. Она может быть оправдана в сложных enterprise-сценариях, но требует:
чёткой архитектурной стратегии, автоматизации, квалифицированного персонала.

Идеал — единая платформа. Реальность — иногда приходится идти на компромиссы. Но компромиссы должны быть управляемыми.
